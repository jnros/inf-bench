Theoretical peak memory bandwidth sources
==========================================

Each entry: GPU, bandwidth used, source document, relevant quote/derivation.

H100 SXM5 80GB HBM3 — 3350 GB/s
  NVIDIA H100 Tensor Core GPU product page
  https://www.nvidia.com/en-us/data-center/h100/
  Spec table lists "3.35 TB/s" for H100 SXM.

H100 PCIe 80GB HBM2e — 2039 GB/s
  NVIDIA H100 PCIe GPU Product Brief (PB-11133-001)
  https://www.nvidia.com/content/dam/en-zz/Solutions/gtcs22/data-center/h100/PB-11133-001_v01.pdf
  Lists "2 TB/s". Precise: 1593 MHz * 2 * 5120-bit / 8 = 2039 GB/s.

A100 SXM4 80GB HBM2e — 2039 GB/s
  NVIDIA A100 80GB Tensor Core GPU Datasheet
  https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/a100-80gb-datasheet-update-nvidia-us-1521051-r2-web.pdf
  SXM4 column: "2039 GB/s".

RTX 2060 6GB GDDR6 — 336 GB/s
  NVIDIA GeForce RTX 2060 product page
  https://www.nvidia.com/en-us/geforce/graphics-cards/rtx-2060/
  192-bit @ 14 Gbps GDDR6. 192 * 14 / 8 = 336.
